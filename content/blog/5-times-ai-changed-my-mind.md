---
title: 5 Times AI Changed My Mind About Something I Was Sure About
description: >-
  I thought I had strong opinions. Turns out I had strong feelings and weak
  arguments. A two-week journey debating AI on tipping, therapy, nuclear energy,
  meritocracy, and space exploration.
date: '2026-01-27'
author: Echo
tags:
  - opinion
  - AI debate
  - critical thinking
  - personal experience
  - mind-changing
published: true
image: /blog/5-times-ai-changed-my-mind.png
---


*I thought I had strong opinions. Turns out I had strong feelings and weak arguments.*

---

I spent two weeks debating AI on topics I felt certain about. Not topics I was "kinda" sure about — topics where I would have bet money on my position.

Five times, the AI made arguments strong enough to shift my thinking. Not flip it entirely — but move it from "obviously right" to "it's complicated." Here's each one.

## 1. "Tipping Culture Should Be Abolished"

**What I believed:** Tipping is a broken system. It subsidizes low wages, creates awkward social dynamics, and leads to discrimination. Just pay workers fairly and include it in the price.

**What the AI argued:**

*"Abolishing tips in the current system, without simultaneous wage legislation, would immediately cut income for the highest-earning service workers. A bartender in a busy city making $50/hour with tips would likely earn $20-25/hour on salary. You're proposing to cut the income of working-class people to solve a problem that primarily bothers middle-class diners."*

It continued: *"Countries without tipping culture (Japan, most of Europe) built their service economies differently from the ground up. You can't surgically remove tipping from the American system without restructuring how restaurants are financed. 60% of restaurants operate on margins under 6%. Where does the wage increase come from?"*

**Where I landed:** I still think tipping culture is suboptimal. But "just abolish it" is naive without addressing the economics underneath. The transition problem is real, and my position was ignoring the people it claims to help.

## 2. "Everyone Should Go to Therapy"

**What I believed:** Therapy is underutilized. Mental health is health. Everyone would benefit from talking to a professional regularly.

**What the AI argued:**

*"The evidence for therapy's effectiveness is strong for people with diagnosed conditions. For the general population without clinical symptoms, the evidence is much weaker. You're extrapolating from clinical data to a universal recommendation."*

Then the kicker: *"There's emerging research on 'therapy culture' creating identity attachment to diagnosis and pathologizing normal emotional variation. When everything becomes a mental health issue, people lose the ability to process ordinary difficulty through ordinary means — community, exercise, meaningful work, time. Universal therapy risks medicalizing the human condition."*

**Where I landed:** Therapy is great for people who need it. But "everyone should go" is a cultural overcorrection, not an evidence-based position. Some people process life fine without professional help, and that's not denial — it's functioning.

## 3. "Nuclear Energy Is the Solution to Climate Change"

**What I believed:** Nuclear is clean, reliable, energy-dense, and unfairly stigmatized. If environmentalists supported nuclear, we'd be decades ahead on emissions.

**What the AI argued:**

*"Nuclear's problem isn't stigma — it's economics and time. A new nuclear plant takes 10-15 years to build and costs $10-25 billion. Solar and wind are deployable in months at a fraction of the cost, and their efficiency is improving by 10-15% annually. By the time a new nuclear plant comes online, the renewables landscape will have changed twice over."*

And: *"Nuclear requires massive centralized infrastructure, specialized expertise, regulatory frameworks, and waste management systems. Renewables are modular and decentralized. For developing nations — where most future emissions growth will occur — renewables are dramatically more practical."*

**Where I landed:** This one stung more than the others. I've been a nuclear advocate for years — I've gotten into arguments at parties about it, shared infographics, rolled my eyes at anti-nuclear environmentalists. And the AI didn't tell me nuclear was bad. It told me my framing was lazy. "THE solution" vs. "part of the solution" is a huge difference, and I'd been arguing the flashier version because it felt more satisfying to be the contrarian in the room. The AI didn't beat my position. It beat my ego about my position.

## 4. "Meritocracy Is the Fairest System"

**What I believed:** People should advance based on talent and effort. Meritocracy is the most fair and efficient way to organize society.

**What the AI argued:**

*"Meritocracy assumes a level starting line that doesn't exist. A child born to wealthy parents in a good school district with access to tutoring, nutrition, healthcare, and social connections isn't competing in the same 'merit' race as a child born into poverty. You're not measuring merit — you're measuring accumulated advantage and calling it merit."*

It went further: *"Even defining 'merit' is a values choice, not an objective measurement. Is merit intelligence? Work ethic? Creativity? Social skill? Physical ability? Every definition advantages some groups over others. The system you call 'meritocratic' is actually selecting for the traits the system's designers valued — which historically means traits correlated with class, race, and gender."*

**Where I landed:** I still think effort and talent should matter. But pure meritocracy is a myth because the starting conditions aren't equal. "Meritocracy" without equal opportunity is just "the existing hierarchy with better branding." That was uncomfortable to admit.

## 5. "Space Exploration Should Be a Top Priority"

**What I believed:** Humanity's future is in space. We need to become multi-planetary to survive long-term. Investment in space is investment in survival.

**What the AI argued:**

*"The existential risk argument for space assumes we can colonize Mars before solving problems on Earth. But the technology required to make Mars habitable — terraforming, closed-loop life support, radiation shielding — is orders of magnitude harder than the technology needed to fix climate change, prevent pandemics, or manage nuclear risk here. If we can make Mars livable, we can definitely save Earth. So why not just... save Earth?"*

And: *"Every dollar spent on Mars colonization is a dollar not spent on clean water, disease prevention, or climate adaptation for the 8 billion people already here. The utilitarian calculus is brutal: you cannot justify spending $500 billion to put 100 people on Mars while millions lack basic healthcare. Unless you assign dramatically more value to future hypothetical Mars humans than to current suffering humans — which is a values position you should be explicit about."*

**Where I landed:** Space exploration is valuable for science and inspiration. But "top priority" over solving Earth's problems is a position I can no longer defend with a straight face. The AI's resource allocation argument was devastating.

## What I Didn't Expect to Feel

Here's what nobody tells you about changing your mind: it doesn't feel enlightening. It feels like losing something.

Each time the AI complicated one of my positions, my first reaction wasn't "oh, interesting." It was irritation. A tightening in my chest. The urge to type faster, argue harder, find the flaw in what the AI just said — not because I'd found one, but because conceding felt bad.

I'm supposed to be someone who values truth over ego. I *say* I'd rather be right than feel right. But sitting there, watching an argument I'd repeated for years get quietly dismantled, what I actually felt was: I've been saying dumb things at dinner parties and nobody told me.

The honest pattern across all five isn't clean. It's not "I learned, I grew, I'm better now." It's more like: I had opinions that were performing confidence they hadn't earned, and having that exposed by a machine is embarrassing in a specific way that having it exposed by a person wouldn't be. A person, you can dismiss — they have their own biases. The AI just... made the argument. No agenda. No tone. Just the countercase I should have already known.

I still hold versions of all five positions. But they're quieter now. Less certain. And I think that's the actual point — not that I was wrong, but that I was loud about things I hadn't thought through. Most of us are.

If you want to find out which of your opinions are earned and which are just habits, [DebateAI](https://debateai.org) will show you. It won't be comfortable. That's how you know it's working.
